# -*- coding: utf-8 -*-
"""money_TF1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jNHRbofFJUxba-GaZ6aAOWSgu46UjU4h

# <div align = center>التّأكّد من سلامة الأوراق النّقديّة

<hr>

# I.    HEADERS (المكتبات)

# II.   DATA (البيانات)

# III. GRAPH (الهيكل)

# IV. SESSION (التطبيق)

<hr>

<hr>

# I - Headers

## I - 1 Librairies
"""

import tensorflow.compat.v1 as tf
tf.disable_v2_behavior() 
import pandas as pan
import numpy as np

"""## I - 2 Initialization"""

# Learning rate
alpha = 0.01

# Number of interations
epoch=20001

# Step
Display_Step = 1000

"""# II - Data

## II - 1 Loading Data
"""

from google.colab import drive
drive.mount('/content/drive/')

data = pan.read_csv('/content/drive/My Drive/data/money.csv')

"""## II - 2 Data Summary"""

data.describe()

"""## II - 3 Display Data"""

data.head(7)

"""## II-4 Split Training Data into input and output"""

X=data.loc[:, ['X1', 'X2', 'X3', 'X4']].values
Y=data.loc[:, ["Label1", "Label2"]].values

"""## II-5 Split Training Data into Training set and Test set

### II-5-A Training Set
"""

x_train=data.loc[0:1000, ['X1', 'X2', 'X3', 'X4']].values
y_train=data.loc[0:1000, ["Label1", "Label2"]].values

"""### II-5-B Test Set"""

x_test=data.loc[1001:len(data), ['X1', 'X2', 'X3', 'X4']].values
y_test=data.loc[1001:len(data), ["Label1", "Label2"]].values

"""# III - Graph

## III-1 placeholders (input has 4 features and output has 2 classes)
"""

x_inp=tf.placeholder(tf.float32,shape=[None, 4])
y_inp=tf.placeholder(tf.float32,shape=[None, 2])

"""## III-2 Variables. (#weight and bias)

![](https://drive.google.com/uc?export=view&id=1se1dUcgfLB089ZRD5DNcBtF2JxQQ1LA9)
"""

W1=tf.Variable(tf.random_normal([4,4]))
b1=tf.Variable(tf.random_normal([4]))

W2=tf.Variable(tf.random_normal([4,2]))
b2=tf.Variable(tf.random_normal([2]))

"""## III-3 Model (One Hidden Layer & SoftMax Function)

![](https://drive.google.com/uc?export=view&id=1vSa358IMFF6l8qaSUxUKajkOrDtflrZ6)
"""

z1 = tf.matmul(x_inp, W1) + b1
a1 = tf.nn.sigmoid(z1)

z2 = tf.matmul(a1, W2) + b2
a2 = tf.nn.sigmoid(z2)

y = tf.nn.softmax(a2)

"""## III-4 Loss function. (Cross Entropy)"""

cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_inp * tf.log(y), reduction_indices=[1]))

"""## III-5 Optimiser. """

optimizer = tf.train.GradientDescentOptimizer(alpha).minimize(cross_entropy)

"""## III-6 Calculating accuracy of our model . """

correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_inp,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

"""# VI- Session

## VI-1 Start Session
"""

sess = tf.Session()

"""## VI-2 Initialising variables"""

sess.run(tf.global_variables_initializer())

"""## VI-3 Training"""

for step in range(epoch):
   _, err = sess.run([optimizer,cross_entropy], feed_dict={x_inp: x_train, y_inp: y_train})

   if step%Display_Step==0 :
       print (step,':', err)

"""## VI-4 Accuracy"""

print (sess.run(accuracy,feed_dict={x_inp: x_test, y_inp:y_test}))