# -*- coding: utf-8 -*-
"""CNN_05_Normalization_Batch_Normalization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nA5Lo2UwJCQLjFMHR8e_ABHn2iXoDmle

# <div align = center>CIFAR 10:  مجموعة الصور الملونة المصنفة إلى 10 فئات.

<hr>

#1 - المكتبات (Librairies)
"""

from keras.datasets import cifar10 as DS
from tensorflow.keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import categorical_crossentropy
import matplotlib.pyplot as plt
import numpy as np

"""```
# This is formatted as code
```

# 2 - البيانات  (Data)

## 2.1 - تحميل البيانات
"""

(x_train, y_train),(x_test, y_test) = DS.load_data()

print("x_train shape =" , x_train.shape)
print("y_train shape =" , y_train.shape)

print("\nx_test shape =" , x_test.shape)
print("y_test shape =" , y_test.shape)

"""## 2.2 - عرض عينة من البيانات"""

figure = plt.figure()

for i in range(25):
  figure.add_subplot(5, 5, i+1)
  plt.imshow(x_train[i])

plt.show()

"""## 2.3 -  تغيير ترميز المخرجات

### 2.3.1 الترميز الأصلي
"""

print(y_train[0:6])

"""

```
# This is formatted as code
```

### 2.3.1 "One hot encoding"  الترميز """

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
print(y_train[0:6])

"""## 2.4 -  تطبيع المدخلات"""

print(x_train[0][0][0:6])

"""![image.png](data:image/png;base64,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)"""

x_train_mean = np.mean(x_train)
x_train_std = np.std(x_train)
x_train = (x_train - x_train_mean) / x_train_std
x_test = (x_test - x_train_mean) / x_train_std

print(x_train[0][0][0:6])

"""# 3- الشبكة العصبية

## 3.1.1 -  النموذج مع تجميع
"""

model = Sequential([
              Conv2D( 32, kernel_size=(3, 3), padding='valid', activation='relu', input_shape=(32,32,3)),
              MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'),
              BatchNormalization(),

              Conv2D( 64, (3, 3), padding='valid', activation='relu'),
              MaxPooling2D(pool_size=(2,2), strides=1, padding='valid'),
              BatchNormalization(),

              Conv2D(128, (3, 3), padding='valid', activation='relu'),
              MaxPooling2D(pool_size=(2,2), strides=1, padding='valid'),
              BatchNormalization(),

              Conv2D(256, (3, 3), padding='valid', activation='relu'),
              MaxPooling2D(pool_size=(2,2), strides=1, padding='valid'),
              BatchNormalization(),

              Flatten(),        
                     
              Dense(1025, activation='relu'),
              Dense(512, activation='relu'), 
              Dense(256, activation='relu'), 
              Dense(128, activation='relu'), 
              Dense(10, activation='softmax')

])

"""## 3.2 -  تركيب النموذج """

model.compile(
    optimizer = Adam(learning_rate=0.001),
    loss = categorical_crossentropy,
    metrics=['accuracy']
)

"""## 3.3 - تدريب النموذج


"""

nb_epochs = 15

history = model.fit(x_train, y_train, batch_size=128, epochs=nb_epochs, verbose=1, validation_split=0.2)

"""## 3.4 -  التقييم

"""

loss, acc = model.evaluate(x_test, y_test, verbose=1)
print("Accuracy = %0.2f" % (acc*100), "%")

"""## 3.5 -  الرسوم البيانية للتعلم

"""

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left') 
plt.rcParams["figure.figsize"] = (17,7)
plt.show()

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left') 
plt.rcParams["figure.figsize"] = (17,7)
plt.show()